{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with Stemmers\n",
    "\n",
    "Some stemmers tend to be better for certain domains. Do not forget to experiment with different stemmers.\n",
    "\n",
    "Here is a comparison between *Porter* and *Snowball* stemmers that come with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n",
      "caress fli die mule deni die agre own humbl size\n",
      "caress fli die mule deni die agre own humbl size\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "# Let's look at the languages supported by Snowball\n",
    "print(\" \".join(SnowballStemmer.languages))\n",
    "\n",
    "stemmer1 = PorterStemmer()\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "\n",
    "tokens = ['caresses', 'flies', 'dies', 'mules', 'denied', \n",
    "           'died', 'agreed', 'owned', 'humbled', 'sized']\n",
    "\n",
    "print(' '.join([stemmer1.stem(t) for t in tokens]))\n",
    "print(' '.join([stemmer2.stem(t) for t in tokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost identical results! Now let's try a difficult case - *generously* and a few of its misspelings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gener gener gener overgener generosli generusli genor genera gener\n",
      "generous generous generous overgener generosli generusli genor genera general\n"
     ]
    }
   ],
   "source": [
    "tokens = ['generously', 'generous', 'generousness', 'overgenerous',\n",
    "          'generosly', 'generusly', 'genorously', 'genera', 'generally']\n",
    "print(' '.join([stemmer1.stem(t) for t in tokens]))\n",
    "print(' '.join([stemmer2.stem(t) for t in tokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, while the performance of both the stemmers are the same for the misspelt words. The *Snowball* stemmer performs better on the original word and its variations.\n",
    "\n",
    "# More features with Topic Modeling\n",
    "\n",
    "    \n",
    "## What will we be doing?\n",
    "\n",
    "* We'll walk through a basic application of Topic Modeling with LDA\n",
    "* We'll also cover the basic NLP operations necessary for the application\n",
    "    \n",
    "\n",
    "## Let's create some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
    "\n",
    "# compile sample documents into a list\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's fast-forward through pre-processing\n",
    "\n",
    "* After the processing, we'll have *texts* - a tokenized, stopped and stemmed list of words from a single document\n",
    "* Let’s fast forward and loop through all our documents and appended each one to *texts*\n",
    "* So now *texts* is a list of lists, one list for each of our original documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### texts\n",
      "[['brocolli', 'good', 'eat', 'brother', u'like', 'eat', 'good', 'brocolli', 'mother'], ['mother', u'spend', 'lot', 'time', u'drive', 'brother', 'around', u'basebal', u'practic'], ['health', u'expert', 'suggest', u'drive', 'may', u'caus', u'increas', 'tension', 'blood', u'pressur'], ['often', 'feel', u'pressur', 'perform', 'well', 'school', 'mother', 'never', u'seem', 'drive', 'brother', 'better'], ['health', u'profession', 'say', 'brocolli', 'good', 'health']]\n",
      "\n",
      "##### The lines in texts\n",
      "['brocolli', 'good', 'eat', 'brother', u'like', 'eat', 'good', 'brocolli', 'mother']\n",
      "['mother', u'spend', 'lot', 'time', u'drive', 'brother', 'around', u'basebal', u'practic']\n",
      "['health', u'expert', 'suggest', u'drive', 'may', u'caus', u'increas', 'tension', 'blood', u'pressur']\n",
      "['often', 'feel', u'pressur', 'perform', 'well', 'school', 'mother', 'never', u'seem', 'drive', 'brother', 'better']\n",
      "['health', u'profession', 'say', 'brocolli', 'good', 'health']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "    \n",
    "# create sample documents\n",
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\" \n",
    "\n",
    "# compile sample documents into a list\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "print(\"\\n##### texts\")\n",
    "print(texts)\n",
    "\n",
    "print(\"\\n##### The lines in texts\")\n",
    "for line in texts:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "* To generate an LDA model, we need to understand how frequently each term occurs within each document\n",
    "* To do that, we need to construct a document-term matrix with a package called *gensim*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with gensim\n",
    "\n",
    "## Getting started with gensim?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(32 unique tokens: [u'often', u'feel', u'profession', u'drive', u'say']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Dictionary() function traverses texts, assigning a unique integer id to each unique token while also collecting word counts and relevant statistics\n",
    "* To see each token’s unique integer id, try -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'often': 23, u'feel': 24, u'profession': 31, u'drive': 8, u'say': 30, u'pressur': 18, u'basebal': 7, u'seem': 29, u'expert': 14, u'perform': 28, u'suggest': 16, u'better': 27, u'health': 19, u'lot': 9, u'tension': 13, u'good': 1, u'around': 6, u'may': 15, u'mother': 4, u'school': 22, u'blood': 20, u'never': 25, u'increas': 21, u'eat': 5, u'practic': 12, u'brocolli': 0, u'like': 2, u'well': 26, u'brother': 3, u'caus': 17, u'time': 10, u'spend': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, our dictionary must be converted into a [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 2), (2, 1), (3, 1), (4, 1), (5, 2)], [(3, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(8, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)], [(3, 1), (4, 1), (8, 1), (18, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)], [(0, 1), (1, 1), (19, 2), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 2), (2, 1), (3, 1), (4, 1), (5, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 2), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "[(3, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]\n",
      "[(8, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]\n",
      "[(3, 1), (4, 1), (8, 1), (18, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]\n",
      "[(0, 1), (1, 1), (19, 2), (30, 1), (31, 1)]\n"
     ]
    }
   ],
   "source": [
    "for line in corpus:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The doc2bow() function converts dictionary into a bag-of-words\n",
    "* The result, *corpus*, is a list of vectors equal to the number of documents\n",
    "* In each document vector is a series of tuples\n",
    "* The tuples are (term ID, term frequency) pairs\n",
    "* This includes terms that actually occur - terms that do not occur in a document will not appear in that document’s vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Quiz\n",
    "\n",
    "Looking at the data above, please answer the following:\n",
    "* How many times does *basebal* occur in *doc_a*?\n",
    "* How many times does *basebal* occur in *doc_b*?\n",
    "* How many times does *health* occur in *doc_e*?\n",
    "* Give an example of a word that occurs in *doc_a* but doesn't occur in *doc_b*.\n",
    "* How many times does *brother* occur in all the documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the LDA Model\n",
    "\n",
    "*corpus* is a (sparse) document-term matrix and now we’re ready to generate an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to the LDA model\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "* num_topics\n",
    "    - required\n",
    "    - An LDA model requires the user to determine how many topics should be generated\n",
    "    - Our document set is small, so we’re only asking for three topics\n",
    "* id2word\n",
    "    - required\n",
    "    - The LdaModel class requires our previous dictionary to map ids to strings\n",
    "* passes\n",
    "    - optional\n",
    "    - The number of laps the model will take through corpus\n",
    "    - The greater the number of passes, the more accurate the model will be\n",
    "    - A lot of passes can be slow on a very large corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=32, num_topics=3, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.082*\"brocolli\" + 0.082*\"good\" + 0.081*\"brother\" + 0.081*\"mother\" + 0.081*\"eat\" + 0.046*\"lot\" + 0.046*\"time\" + 0.046*\"basebal\" + 0.046*\"practic\" + 0.046*\"around\"'), (1, u'0.125*\"health\" + 0.050*\"increas\" + 0.050*\"may\" + 0.050*\"blood\" + 0.050*\"suggest\" + 0.050*\"caus\" + 0.050*\"tension\" + 0.050*\"expert\" + 0.050*\"say\" + 0.050*\"profession\"'), (2, u'0.059*\"drive\" + 0.059*\"pressur\" + 0.059*\"perform\" + 0.059*\"school\" + 0.059*\"often\" + 0.059*\"never\" + 0.059*\"well\" + 0.059*\"feel\" + 0.059*\"better\" + 0.059*\"seem\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.082*\"brocolli\" + 0.082*\"good\" + 0.081*\"brother\" + 0.081*\"mother\" + 0.081*\"eat\" + 0.046*\"lot\" + 0.046*\"time\" + 0.046*\"basebal\" + 0.046*\"practic\" + 0.046*\"around\"')\n",
      "(2, u'0.059*\"drive\" + 0.059*\"pressur\" + 0.059*\"perform\" + 0.059*\"school\" + 0.059*\"often\" + 0.059*\"never\" + 0.059*\"well\" + 0.059*\"feel\" + 0.059*\"better\" + 0.059*\"seem\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamodel.print_topics(num_topics=2):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.082*\"brocolli\" + 0.082*\"good\" + 0.081*\"brother\"')\n",
      "(1, u'0.125*\"health\" + 0.050*\"increas\" + 0.050*\"may\"')\n",
      "(2, u'0.059*\"drive\" + 0.059*\"pressur\" + 0.059*\"perform\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamodel.print_topics(num_topics=3, num_words=3):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Within each topic are the three most probable words to appear in that topic\n",
    "\n",
    "## Topics in detail\n",
    "Let's now look at a topic in detail. Let us see how distinct the topics are, and if they seem to capture any context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.082*\"brocolli\" + 0.082*\"good\" + 0.081*\"brother\" + 0.081*\"mother\" + 0.081*\"eat\" + 0.046*\"lot\" + 0.046*\"time\" + 0.046*\"basebal\" + 0.046*\"practic\" + 0.046*\"around\"\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topic(topicno=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125*\"health\" + 0.050*\"increas\" + 0.050*\"may\" + 0.050*\"blood\" + 0.050*\"suggest\" + 0.050*\"caus\" + 0.050*\"tension\" + 0.050*\"expert\" + 0.050*\"say\" + 0.050*\"profession\"\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topic(topicno=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059*\"drive\" + 0.059*\"pressur\" + 0.059*\"perform\" + 0.059*\"school\" + 0.059*\"often\" + 0.059*\"never\" + 0.059*\"well\" + 0.059*\"feel\" + 0.059*\"better\" + 0.059*\"seem\"\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topic(topicno=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the topics make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.082*\"brocolli\" + 0.082*\"good\" + 0.081*\"brother\"')\n",
      "(1, u'0.125*\"health\" + 0.050*\"increas\" + 0.050*\"may\"')\n",
      "(2, u'0.059*\"drive\" + 0.059*\"pressur\" + 0.059*\"perform\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in ldamodel.print_topics(num_topics=3, num_words=3):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Even though our document set is small the model is reasonable\n",
    "* Third Topic - health, brocolli and good make sense together\n",
    "* Second Topic includes mother and brother, which is reasonable\n",
    "* First Topic - confusing!\n",
    "    - If we revisit the original documents, we see that drive has multiple meanings\n",
    "        * driving a car\n",
    "        * driving oneself to improve\n",
    "    - This is something to note\n",
    "* Two topics seems like a better fit for our documents!\n",
    "\n",
    "## Refining the model\n",
    "\n",
    "Two topics seems like a better fit for our documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.109*\"health\" + 0.047*\"pressur\" + 0.047*\"drive\" + 0.047*\"may\"')\n",
      "(1, u'0.076*\"mother\" + 0.076*\"brother\" + 0.055*\"brocolli\" + 0.055*\"good\"')\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary, passes=20)\n",
    "\n",
    "for topic in ldamodel.print_topics(num_topics=2, num_words=4):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with more passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.076*\"brother\" + 0.076*\"mother\" + 0.055*\"brocolli\" + 0.055*\"good\"')\n",
      "(1, u'0.109*\"health\" + 0.047*\"pressur\" + 0.047*\"drive\" + 0.047*\"expert\"')\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary, passes=200)\n",
    "\n",
    "for topic in ldamodel.print_topics(num_topics=2, num_words=4):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Topic Modeling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.054*\"good\" + 0.054*\"brocolli\" + 0.053*\"drive\" + 0.053*\"brother\"')\n",
      "(1, u'0.082*\"health\" + 0.048*\"mother\" + 0.048*\"brother\" + 0.048*\"drive\"')\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "    \n",
    "# create sample documents\n",
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\" \n",
    "\n",
    "# compile sample documents into a list\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# generate LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary, passes=20)\n",
    "\n",
    "# print the topics\n",
    "for topic in ldamodel.print_topics(num_topics=2, num_words=4):\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Topic for new documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_f = \"Are Health professionals justified in saying that brocolli is good for your health?\" \n",
    "\n",
    "doc_set = [doc_f]\n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "infer = ldamodel[corpus[0]]\n",
    "\n",
    "# https://radimrehurek.com/gensim/wiki.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.92344832516970621), (1, 0.076551674830293848)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
